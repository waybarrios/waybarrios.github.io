<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="stylesheet" href="style.css" />
  <link rel="icon" type="image/png" href="https://avatars.githubusercontent.com/u/6794828?v=4">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Wayner Barrios - PhD Candidate in Computer Science at Dartmouth College, specializing in Computer Vision, Video Understanding, and Deep Learning">
  <title>Wayner Barrios</title>
</head>

<body class="grayscale">
  <div id="header">
    <img src="https://avatars.githubusercontent.com/u/6794828?v=4" alt="Wayner Barrios" style="width:200px">
    <h1><a href="/">Wayner Barrios</a></h1>
    <p class="subtitle">PhD Candidate ¬∑ Computer Science ¬∑ Dartmouth College</p>
    <p class="nav">
      <a href="/">home</a>
      <a href="https://github.com/waybarrios">github</a>
      <a href="https://scholar.google.com.co/citations?user=MPJZRmsAAAAJ&hl=en">scholar</a>     
      <a href="https://www.wiqonn.com/" target="_blank">wiqonn</a>
      <a href="https://discord.com/users/waybarrios" target="_blank">discord</a>
    </p>
    <hr>
  </div>
  
  <div id="main">
    <section id="about">
      <h2>About</h2>
      <p>I'm a PhD researcher in Computer Science at <a href="https://home.dartmouth.edu/" target="_blank">Dartmouth College</a>, advised by <a href="https://souyoungjin.github.io/" target="_blank">SouYoung Jin</a>. My research focuses on <strong>Multimodal Large Language Models (MLLMs)</strong> and <strong>computer vision</strong>, with emphasis on evaluation, step-verified reasoning, and improved multimodal fusion through learnable masks, cross-modal alignment, and guidance mechanisms for long-video understanding.</p>
      
      <p>I have extensive experience in <strong>video understanding</strong> and building <strong>AI datasets end-to-end</strong>‚Äîfrom specifications and tooling development to quality assurance and benchmark release. As a <strong>Python open-source contributor</strong>, I've contributed to projects that advance the computer vision and geospatial communities.</p>

      <p>During Winter 2025, I was a research intern at <strong>Samsung Research America</strong>, working on <strong>Reinforcement Learning</strong> and <strong>Multimodal Large Language Models</strong>.</p>

      <p>Beyond research, I support <strong>US and Latin American clients</strong> on data and business analytics (KPI decisions, market forecasting) and automation of AI/ML pipelines. I've delivered real-world systems that process <strong>large-scale, real-time data</strong> for many concurrent users, leveraging distributed training and inference.</p>
    </section>

    <section id="research-interests">
      <h2>Research Interests</h2>
      <ul>
        <li>Multimodal Large Language Models (MLLMs) & Vision-Language Models</li>
        <li>Evaluation & Step-Verified Reasoning in AI Systems</li>
        <li>Multimodal Fusion: Learnable Masks & Cross-Modal Alignment</li>
        <li>Video Understanding & Long-Video Guidance Mechanisms</li>
        <li>Temporal Reasoning & Activity Recognition</li>
        <li>Deep Learning & Neural Architectures</li>
      </ul>
    </section>

    <section id="technical-expertise">
      <h2>Technical Expertise</h2>
      <div class="skills-grid">
        <div class="skill-category">
          <h3>Deep Learning Frameworks</h3>
          <p>PyTorch ‚Ä¢ JAX ‚Ä¢ TensorFlow</p>
        </div>
        <div class="skill-category">
          <h3>Model Development</h3>
          <p>Pretraining ‚Ä¢ Post-training ‚Ä¢ Fine-tuning ‚Ä¢ RLHF</p>
        </div>
        <div class="skill-category">
          <h3>Distributed Systems</h3>
          <p>Distributed Training ‚Ä¢ Distributed Inference ‚Ä¢ Large-Scale Data Processing</p>
        </div>
        <div class="skill-category">
          <h3>AI Infrastructure</h3>
          <p>Real-time Systems ‚Ä¢ ML Pipeline Automation ‚Ä¢ Production Deployment</p>
        </div>
        <div class="skill-category">
          <h3>Data & Analytics</h3>
          <p>Dataset Engineering ‚Ä¢ KPI Analysis ‚Ä¢ Market Forecasting ‚Ä¢ Business Intelligence</p>
        </div>
        <div class="skill-category">
          <h3>Software Engineering</h3>
          <p>Python ‚Ä¢ Open Source Contributions ‚Ä¢ API Development ‚Ä¢ System Architecture</p>
        </div>
      </div>
    </section>

    <section id="publications">
      <h2>Selected Publications</h2>
      
      <div class="publication">
        <p class="pub-title"><a href="https://arxiv.org/abs/2506.01850">MoDA: Modulation Adapter for Fine-Grained Visual Grounding in Instructional MLLMs</a></p>
        <p class="pub-authors"><strong>Wayner Barrios</strong>, Andr√©s Villa, Juan Le√≥n Alc√°zar, SouYoung Jin, Bernard Ghanem</p>
        <p class="pub-venue">arXiv preprint, 2025</p>
        <p class="pub-description">Proposes a lightweight module designed to refine pre-aligned visual features through instruction-guided modulation. MoDA employs a Transformer-based cross-attention mechanism to generate modulation masks over aligned visual tokens, emphasizing semantically relevant embedding dimensions based on language instructions. This enhances fine-grained visual grounding capabilities in Multimodal Large Language Models.</p>
      </div>

      <div class="publication">
        <p class="pub-title"><a href="https://arxiv.org/abs/2312.05430">FT2TF: First-Person Statement Text-To-Talking Face Generation</a></p>
        <p class="pub-authors">Xingjian Diao, Ming Cheng, <strong>Wayner Barrios</strong>, SouYoung Jin</p>
        <p class="pub-venue">WACV 2025</p>
        <p class="pub-description">Addresses the challenge of generating realistic talking face videos from first-person statements, contributing to the advancement of multimodal generation systems.</p>
      </div>

      <div class="publication">
        <p class="pub-title"><a href="https://arxiv.org/abs/2406.02761">Multi-layer Learnable Attention Mask for Multimodal Tasks</a></p>
        <p class="pub-authors"><strong>Wayner Barrios</strong>, SouYoung Jin</p>
        <p class="pub-venue">arXiv preprint, 2024</p>
        <p class="pub-description">Introduces a learnable attention mask (LAM) mechanism that optimizes attention maps and focuses on critical tokens across multiple layers of Transformer networks. Leveraging self-attention modules in BERT-like architectures, LAM accommodates varied information aspects embedded at each layer. Experimental validation on MADv2, QVHighlights, ImageNet 1K, and MSRVTT demonstrates effectiveness in enhancing model performance while reducing redundant computations, particularly for complex multimodal scenarios including movie understanding.</p>
      </div>

      <div class="publication">
        <p class="pub-title"><a href="https://arxiv.org/abs/2302.13372">Localizing Moments in Long Video Via Multimodal Guidance</a></p>
        <p class="pub-authors"><strong>Wayner Barrios</strong>, Mattia Soldan, Alberto Mario Ceballos-Arroyo, Fabian Caba Heilbron, Bernard Ghanem</p>
        <p class="pub-venue">ICCV 2023</p>
        <p class="pub-description">Proposes a novel approach for temporal localization of specific moments in long-form videos using multimodal guidance, addressing challenges in video understanding and moment retrieval.</p>
      </div>


      <div class="publication">
        <p class="pub-title"><a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Caba_Heilbron_SCC_Semantic_Context_CVPR_2017_paper.pdf">SCC: Semantic Context Cascade for Efficient Action Detection</a></p>
        <p class="pub-authors">Fabian Caba Heilbron, <strong>Wayner Barrios</strong>, Victor Escorcia, Bernard Ghanem</p>
        <p class="pub-venue">CVPR 2017</p>
      </div>

      <p class="more-pubs">‚Üí Full list on <a href="https://scholar.google.com.co/citations?user=MPJZRmsAAAAJ&hl=en">Google Scholar</a></p>
    </section>

    <section id="projects">
      <h2>Selected Projects</h2>
      
      <div class="project">
        <p class="project-title"><a href="https://activity-net.org">ActivityNet</a></p>
        <p>Large-scale benchmark for human activity understanding in videos. Developed algorithms and interfaces for video collection, temporal annotation, QA processes, and evaluation infrastructure.</p>
      </div>

      <div class="project">
        <p class="project-title"><a href="https://www.iarpa.gov/index.php/research-programs/diva">Deep Intermodal Video Analytics (DIVA)</a></p>
        <p>IARPA-funded program for automated activity detection in multi-camera streaming video. Designed computer vision algorithms for complex activity recognition across diverse camera viewpoints. Participated in the ActEv Challenge at CVPR'19 ActivityNet workshop with CMU team.</p>
      </div>

      <div class="project">
        <p class="project-title"><a href="https://github.com/GeoNode/geonode">GeoNode - Open Source Geospatial Platform</a></p>
        <p>Contributed to GeoNode, an open source platform that facilitates the creation, sharing, and collaborative use of geospatial data. My contributions focused on service virtualization, inter-service networking communications, and advancing open source GIS technology for the global community.</p>
      </div>

      <div class="project">
        <p class="project-title"><a href="https://github.com/cga-harvard/worldmap">Harvard WorldMap</a></p>
        <p>Open source geospatial data platform developed to lower barriers for scholars working with geospatial information. Optimized large-scale workloads for production, developed visualization tools for big geospatial data, and managed complex migration processes.</p>
      </div>

      <div class="project">
        <p class="project-title"><a href="https://vivamed.com.co/humathcurie/">VivaMed - HUMATH: Telemedicine Pneumonia Detection</a></p>
        <p>COVID-19 detection system using medical imaging for Colombian hospitals. Led ML model deployment, computer vision architecture, and data privacy implementation. Sponsored by Colombian Ministry of Science, Technology and Innovation.</p>
      </div>
    </section>

    <section id="entrepreneurship">
      <h2>Entrepreneurship</h2>
      <p>I founded <a href="https://wiqonn.com" target="_blank"><strong>Wiqonn</strong></a>, a technology startup based in Latin America, specializing in artificial intelligence, data analysis, and software development solutions.</p>
    </section>

    <section id="personal">
      <h2>Beyond Research</h2>
      <ul>
        <li>üêï Dog lover: Tala, Luna, Raissa & Naia</li>
        <li>üåç Passionate traveler exploring cultures worldwide</li>
        <li>üéµ Audiophile & amateur musician</li>
        <li>üåä Water sports enthusiast ‚Äî always better near the sea</li>
        <li>üîß Tech tinkerer with interest in reverse engineering</li>
      </ul>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <ul>
        <li>Academic: <a href="mailto:way.gr@dartmouth.edu">way.gr@dartmouth.edu</a></li>
        <li>Personal: <a href="mailto:waybarrios@gmail.com">waybarrios@gmail.com</a></li>
        <li>Business: <a href="mailto:wbarriosq@wiqonn.com">wbarriosq@wiqonn.com</a></li>
        <li>GitHub: <a href="https://github.com/waybarrios">waybarrios</a></li>
        <li>Scholar: <a href="https://scholar.google.com.co/citations?user=MPJZRmsAAAAJ&hl=en">Google Scholar</a></li>
      </ul>
    </section>
  </div>

  <div id="footer">
    <hr>
    <p>¬© 2025 Wayner Barrios ¬∑ Last updated: November 2025</p>
  </div>
</body>
</html>

